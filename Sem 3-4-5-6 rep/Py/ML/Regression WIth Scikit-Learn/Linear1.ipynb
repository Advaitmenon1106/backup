{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Wind     Power\n",
      "0    1.096875  0.000000\n",
      "1    1.735069  0.354646\n",
      "2    4.610486  2.378792\n",
      "3    4.668333  1.859271\n",
      "4    4.695903  2.842979\n",
      "..        ...       ...\n",
      "360  4.394097  1.638833\n",
      "361  4.419931  1.960583\n",
      "362  4.458194  1.657208\n",
      "363  4.482500  1.766604\n",
      "364  4.545764  2.424187\n",
      "\n",
      "[365 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Windmill1.csv\")\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[\"Wind\"]\n",
    "Y_train = df[\"Power\"]\n",
    "X_train = X_train/max(X_train)\n",
    "Y = X_train/max(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.05988489 0.0947277  0.25171371 0.25487193 0.25637711 0.25656668\n 0.25857611 0.25942917 0.26264426 0.262758   0.26309544 0.26481672\n 0.09609639 0.26579111 0.26654939 0.26964695 0.27345349 0.27963724\n 0.28015287 0.28063058 0.28262485 0.28505513 0.28711385 0.09725276\n 0.2884977  0.29101139 0.29199336 0.29231563 0.2947004  0.29630795\n 0.29793445 0.29846146 0.29878752 0.29986806 0.09886789 0.30082349\n 0.30124054 0.30321206 0.30748874 0.31081378 0.31225072 0.31312273\n 0.31458621 0.31590561 0.32394713 0.0989096  0.32604377 0.33026737\n 0.33163985 0.33376681 0.33424832 0.33501418 0.33718285 0.33975341\n 0.3438064  0.34705561 0.09975508 0.34746508 0.3483826  0.34854183\n 0.34986124 0.35343651 0.35352371 0.35375499 0.35389527 0.35521088\n 0.35825915 0.10045269 0.36053777 0.36058327 0.36137946 0.36142874\n 0.36162969 0.36235384 0.36401068 0.36511397 0.36517084 0.36639166\n 0.10250004 0.36746463 0.36944752 0.37034608 0.37091478 0.37270053\n 0.37601419 0.37947194 0.38088991 0.38145862 0.38216003 0.10320144\n 0.38332019 0.38433628 0.38473817 0.38575426 0.38670969 0.39019776\n 0.39155128 0.39415217 0.39696917 0.39901652 0.10531324 0.40051032\n 0.40268278 0.40731206 0.40790352 0.41232048 0.41304084 0.41338965\n 0.41390528 0.42090417 0.42443774 0.06723639 0.10932832 0.42618177\n 0.42712583 0.42723199 0.42791823 0.42873337 0.43271433 0.43391999\n 0.43403752 0.43663083 0.44126769 0.10971125 0.44260225 0.44446382\n 0.44487708 0.44507424 0.44845236 0.44848269 0.44916893 0.44947224\n 0.45225511 0.4533622  0.11186475 0.45358968 0.45480672 0.45485979\n 0.45611474 0.46077435 0.46094496 0.46096392 0.46177907 0.46263971\n 0.46268142 0.11246    0.46753818 0.46862251 0.46991917 0.47447641\n 0.47518161 0.47625078 0.47872655 0.4797616  0.48255206 0.48446291\n 0.11294151 0.48644581 0.48798132 0.48844007 0.48889125 0.49082864\n 0.49336508 0.4949423  0.49927585 0.50077344 0.5025061  0.11332823\n 0.50412502 0.50416673 0.5053231  0.50537618 0.50590318 0.50610034\n 0.50704439 0.50733633 0.50931922 0.51116562 0.11359362 0.51336462\n 0.51344045 0.51428593 0.51537027 0.5162347  0.5174669  0.51904412\n 0.51950287 0.52145923 0.52705152 0.11523908 0.52733966 0.52931497\n 0.53114242 0.53455466 0.53635936 0.5365641  0.53932043 0.53932422\n 0.54263031 0.5454056  0.1161111  0.54951546 0.5499363  0.55114576\n 0.55934652 0.56020716 0.56712643 0.57119838 0.57143345 0.57275285\n 0.57342771 0.11886744 0.57428077 0.57480019 0.57575562 0.57770818\n 0.5801233  0.58444547 0.58465779 0.58471087 0.58527958 0.58645491\n 0.06961737 0.12109298 0.58660277 0.58795629 0.59421966 0.59467462\n 0.59564901 0.59678642 0.59926599 0.59995602 0.60400143 0.60455497\n 0.12197258 0.61236901 0.61345713 0.61406755 0.61582675 0.61689592\n 0.6171234  0.61794992 0.61997073 0.62424741 0.62461897 0.12633267\n 0.62762553 0.62955156 0.63074205 0.63199321 0.63214865 0.63217898\n 0.6338889  0.63918925 0.6454602  0.64996057 0.12672318 0.66204371\n 0.6629688  0.67176102 0.67259513 0.677668   0.67875612 0.67901773\n 0.68090584 0.68134564 0.68136839 0.12845205 0.69258709 0.69621923\n 0.69968835 0.71242739 0.71943766 0.72277408 0.72575411 0.75141039\n 0.75218005 0.75833346 0.12855063 0.76613992 0.77283929 0.77653968\n 0.78039552 0.78069504 0.78471769 0.78819439 0.79921594 0.80712856\n 0.81535207 0.13813525 0.82812145 0.83245879 0.83356208 0.89247638\n 0.90497278 1.         0.1388594  0.14018638 0.14243847 0.07454996\n 0.14323845 0.14525167 0.14649904 0.14929708 0.14961935 0.15226952\n 0.15440786 0.15963618 0.16364367 0.16704075 0.075767   0.16747297\n 0.16834119 0.16862934 0.17035821 0.17092313 0.17317521 0.17529459\n 0.17635239 0.17764904 0.17910493 0.08463125 0.18013998 0.18063665\n 0.18287356 0.18351052 0.18487542 0.18855306 0.18967151 0.18970943\n 0.19014165 0.1935501  0.08536678 0.19674624 0.19730357 0.19892249\n 0.19943433 0.19967318 0.20022672 0.2003253  0.20181152 0.20184565\n 0.20301339 0.08769469 0.20948149 0.20959144 0.21023977 0.21033076\n 0.21093738 0.21148334 0.21381504 0.21772775 0.2194642  0.22267929\n 0.09172872 0.23027723 0.2309066  0.23123265 0.23434917 0.23608183\n 0.23989976 0.24131015 0.2433992  0.24472619 0.24818014].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m reg \u001b[39m=\u001b[39m linear_model\u001b[39m.\u001b[39mLinearRegression()\n\u001b[1;32m----> 2\u001b[0m reg\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n",
      "File \u001b[1;32mc:\\Users\\Kavita manoj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:684\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    680\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[0;32m    682\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 684\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    685\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    686\u001b[0m )\n\u001b[0;32m    688\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    689\u001b[0m     sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype, only_non_negative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    690\u001b[0m )\n\u001b[0;32m    692\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[39m=\u001b[39m _preprocess_data(\n\u001b[0;32m    693\u001b[0m     X,\n\u001b[0;32m    694\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    698\u001b[0m     sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[0;32m    699\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Kavita manoj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Kavita manoj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1072\u001b[0m     )\n\u001b[1;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1075\u001b[0m     X,\n\u001b[0;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1088\u001b[0m )\n\u001b[0;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\Kavita manoj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    878\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 879\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    880\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    881\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    882\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    884\u001b[0m         )\n\u001b[0;32m    886\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    890\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.05988489 0.0947277  0.25171371 0.25487193 0.25637711 0.25656668\n 0.25857611 0.25942917 0.26264426 0.262758   0.26309544 0.26481672\n 0.09609639 0.26579111 0.26654939 0.26964695 0.27345349 0.27963724\n 0.28015287 0.28063058 0.28262485 0.28505513 0.28711385 0.09725276\n 0.2884977  0.29101139 0.29199336 0.29231563 0.2947004  0.29630795\n 0.29793445 0.29846146 0.29878752 0.29986806 0.09886789 0.30082349\n 0.30124054 0.30321206 0.30748874 0.31081378 0.31225072 0.31312273\n 0.31458621 0.31590561 0.32394713 0.0989096  0.32604377 0.33026737\n 0.33163985 0.33376681 0.33424832 0.33501418 0.33718285 0.33975341\n 0.3438064  0.34705561 0.09975508 0.34746508 0.3483826  0.34854183\n 0.34986124 0.35343651 0.35352371 0.35375499 0.35389527 0.35521088\n 0.35825915 0.10045269 0.36053777 0.36058327 0.36137946 0.36142874\n 0.36162969 0.36235384 0.36401068 0.36511397 0.36517084 0.36639166\n 0.10250004 0.36746463 0.36944752 0.37034608 0.37091478 0.37270053\n 0.37601419 0.37947194 0.38088991 0.38145862 0.38216003 0.10320144\n 0.38332019 0.38433628 0.38473817 0.38575426 0.38670969 0.39019776\n 0.39155128 0.39415217 0.39696917 0.39901652 0.10531324 0.40051032\n 0.40268278 0.40731206 0.40790352 0.41232048 0.41304084 0.41338965\n 0.41390528 0.42090417 0.42443774 0.06723639 0.10932832 0.42618177\n 0.42712583 0.42723199 0.42791823 0.42873337 0.43271433 0.43391999\n 0.43403752 0.43663083 0.44126769 0.10971125 0.44260225 0.44446382\n 0.44487708 0.44507424 0.44845236 0.44848269 0.44916893 0.44947224\n 0.45225511 0.4533622  0.11186475 0.45358968 0.45480672 0.45485979\n 0.45611474 0.46077435 0.46094496 0.46096392 0.46177907 0.46263971\n 0.46268142 0.11246    0.46753818 0.46862251 0.46991917 0.47447641\n 0.47518161 0.47625078 0.47872655 0.4797616  0.48255206 0.48446291\n 0.11294151 0.48644581 0.48798132 0.48844007 0.48889125 0.49082864\n 0.49336508 0.4949423  0.49927585 0.50077344 0.5025061  0.11332823\n 0.50412502 0.50416673 0.5053231  0.50537618 0.50590318 0.50610034\n 0.50704439 0.50733633 0.50931922 0.51116562 0.11359362 0.51336462\n 0.51344045 0.51428593 0.51537027 0.5162347  0.5174669  0.51904412\n 0.51950287 0.52145923 0.52705152 0.11523908 0.52733966 0.52931497\n 0.53114242 0.53455466 0.53635936 0.5365641  0.53932043 0.53932422\n 0.54263031 0.5454056  0.1161111  0.54951546 0.5499363  0.55114576\n 0.55934652 0.56020716 0.56712643 0.57119838 0.57143345 0.57275285\n 0.57342771 0.11886744 0.57428077 0.57480019 0.57575562 0.57770818\n 0.5801233  0.58444547 0.58465779 0.58471087 0.58527958 0.58645491\n 0.06961737 0.12109298 0.58660277 0.58795629 0.59421966 0.59467462\n 0.59564901 0.59678642 0.59926599 0.59995602 0.60400143 0.60455497\n 0.12197258 0.61236901 0.61345713 0.61406755 0.61582675 0.61689592\n 0.6171234  0.61794992 0.61997073 0.62424741 0.62461897 0.12633267\n 0.62762553 0.62955156 0.63074205 0.63199321 0.63214865 0.63217898\n 0.6338889  0.63918925 0.6454602  0.64996057 0.12672318 0.66204371\n 0.6629688  0.67176102 0.67259513 0.677668   0.67875612 0.67901773\n 0.68090584 0.68134564 0.68136839 0.12845205 0.69258709 0.69621923\n 0.69968835 0.71242739 0.71943766 0.72277408 0.72575411 0.75141039\n 0.75218005 0.75833346 0.12855063 0.76613992 0.77283929 0.77653968\n 0.78039552 0.78069504 0.78471769 0.78819439 0.79921594 0.80712856\n 0.81535207 0.13813525 0.82812145 0.83245879 0.83356208 0.89247638\n 0.90497278 1.         0.1388594  0.14018638 0.14243847 0.07454996\n 0.14323845 0.14525167 0.14649904 0.14929708 0.14961935 0.15226952\n 0.15440786 0.15963618 0.16364367 0.16704075 0.075767   0.16747297\n 0.16834119 0.16862934 0.17035821 0.17092313 0.17317521 0.17529459\n 0.17635239 0.17764904 0.17910493 0.08463125 0.18013998 0.18063665\n 0.18287356 0.18351052 0.18487542 0.18855306 0.18967151 0.18970943\n 0.19014165 0.1935501  0.08536678 0.19674624 0.19730357 0.19892249\n 0.19943433 0.19967318 0.20022672 0.2003253  0.20181152 0.20184565\n 0.20301339 0.08769469 0.20948149 0.20959144 0.21023977 0.21033076\n 0.21093738 0.21148334 0.21381504 0.21772775 0.2194642  0.22267929\n 0.09172872 0.23027723 0.2309066  0.23123265 0.23434917 0.23608183\n 0.23989976 0.24131015 0.2433992  0.24472619 0.24818014].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train, Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79faa210a4d4b910022c04f6ce8980c16d31a28838e0d99a1f5f82f062c85742"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
